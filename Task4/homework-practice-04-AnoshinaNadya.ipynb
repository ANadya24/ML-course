{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ВМК МГУ\n",
    "\n",
    "## Практическое задание 4\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 10.03.2018\n",
    "\n",
    "Мягкий дедлайн: 25.03.2018 (за каждый день просрочки снимается 1 балл)\n",
    "\n",
    "Жесткий дедлайн: 01.04.2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "\n",
    "__Первая часть__ задания посвящена реализации различных слоёв нейронной сети.\n",
    "\n",
    "__Вторая часть__ задания посвящена реализации алгоритма обратного распространения ошибки и обучение нейросети на задаче распознавания рукописных цифр MNIST.\n",
    "\n",
    "__Бонусная часть__ задания посвящена реализации сверточного слоя и пулинга для улучшения решения задачи классификации из предыдущего пункта.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за основную часть работы — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце Вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл *.ipynb в соответствии со следующим форматом: homework-practice-04-Username.ipynb, где Username — Ваша фамилия и имя на латинице именно в таком порядке (например, homework-practice-04-IvanovIvan.ipynb). Модуль с кодом layers.py нужно отправить в Яндекс.Контест, а также ноутбук и layers.py в anytask.\n",
    "\n",
    "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже.\n",
    "\n",
    "Ссылка на яндекс.контест:\n",
    "\n",
    "1. МГУ: https://contest.yandex.ru/contest/7700/problems/\n",
    "2. ВШЭ: https://official.contest.yandex.ru/contest/7700/problems/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оценка:** 10\n",
    "\n",
    "**Номер посылки в контесте:** 10962685"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Реализация слоёв графа вычислений\n",
    "\n",
    "В этом задании мы реализуем граф вычислений для задачи распознавания изображений рукописных цифр на примере датасета [MNIST](http://yann.lecun.com/exdb/mnist/) — в частности, эта часть посвящена реализации всех требующихся для построения графа слоёв.\n",
    "\n",
    "Указанная задача является задачей классификации на $K = 10$ классов, поэтому будем строить граф вычислений, выходной слой которого будет содержать 10 нейронов, $k$-ый из которых вычисляет оценку принадлежности объекта $k$-ому классу. В качестве функционала качества в данной задаче будем использовать **кросс-энтропию**:\n",
    "\n",
    "$$Q(a, X) = \\frac{1}{l}\\sum_{i=1}^l \\sum_{k=1}^K [y_i = k] \\log a_k(x_i),$$\n",
    "где\n",
    "\n",
    "$X = \\{ (x_i, y_i)\\}_{i=1}^l, \\, y_i \\in \\{1, \\dots, K\\},$ — обучающая выборка,\n",
    "\n",
    "$a(x) = (a_k(x))_{k=1}^K \\in \\mathbb{R}^K$ — прогноз графа вычислений для объекта $x$, состоящий из выходов $K$ нейронов выходного слоя (т.е. $a_k(x)$ — оценка принадлежности объекта $x$ классу $k$, построенная при помощи заданного графа вычислений).\n",
    "\n",
    "Нейрнонные сети обучаются с использованием стохастических методов оптимизации, однако для ускорения обучения и большей стабильности за один проход параметры оптимизируются по батчу — набору из нескольких тренировочных примеров, так же batch_size является дополнительной размерностью для входящих в слой тензоров.\n",
    "\n",
    "Для начала определим класс Layer, реализующий тождественный слой, который будет являться базовым классом для всех последующих."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    A building block§. Each layer is capable of performing two things:\n",
    "\n",
    "    - Process input to get output:           output = layer.forward(input)\n",
    "\n",
    "    - Propagate gradients through itself:    grad_input = layer.backward(input, grad_output)\n",
    "\n",
    "    Some layers also have learnable parameters which they update during layer.backward.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Here you can initialize layer parameters (if any) and auxiliary stuff.\n",
    "        \"\"\"\n",
    "\n",
    "        raise NotImplementedError(\"Not implemented in interface\")\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Takes input data of shape [batch, ...], returns output data [batch, ...]\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Not implemented in interface\")\n",
    "\n",
    "    def backward(self, input, grad_output):\n",
    "        \"\"\"\n",
    "        Performs a backpropagation step through the layer, with respect to the given input. Updates layer parameters and returns gradient for next layer\n",
    "        Let x be layer weights, output – output of the layer on the given input and grad_output – gradient of layer with respect to output\n",
    "\n",
    "        To compute loss gradients w.r.t parameters, you need to apply chain rule (backprop):\n",
    "        (d loss / d x)  = (d loss / d output) * (d output / d x)\n",
    "        Luckily, you already receive (d loss / d output) as grad_output, so you only need to multiply it by (d output / d x)\n",
    "        If your layer has parameters (e.g. dense layer), you need to update them here using d loss / d x. The resulting update is a sum of updates in a batch.\n",
    "        \n",
    "        returns (d loss / d input) = (d loss / d output) * (d output / d input)\n",
    "        \"\"\"\n",
    "\n",
    "        raise NotImplementedError(\"Not implemented in interface\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1 (1 балл).**\n",
    "\n",
    "Используя приведенные прототипы, реализуйте слой, применяющий функцию активации ReLU (Rectified Linear Unit) поэлементно к каждому из входов слоя:\n",
    "$$\\text{ReLU}(z) = \\max (0, z)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        ReLU layer simply applies elementwise rectified linear unit to all inputs\n",
    "        This layer does not have any parameters.\n",
    "        \"\"\"\n",
    "#         self.num_inputs = 0\n",
    "#         self.num_outputs = 0       \n",
    "#         raise NotImplementedError(\"Implement me plz ;(\")\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Perform ReLU transformation\n",
    "        input shape: [batch, input_units]\n",
    "        output shape: [batch, input_units]\n",
    "        \"\"\"\n",
    "#         self.num_inputs = input.shape\n",
    "        output = np.zeros(input.shape)\n",
    "        if (input.dtype == np.float):\n",
    "            output = np.clip(input, 0, np.finfo(input.dtype).max)\n",
    "        else:\n",
    "            output = np.clip(input, 0, np.iinfo(input.dtype).max)\n",
    "        return output\n",
    "\n",
    "    def backward(self, input, grad_output):\n",
    "        \"\"\"\n",
    "        Compute gradient of loss w.r.t. ReLU input\n",
    "        \"\"\"\n",
    "        dx, x = None, input\n",
    "        dx = np.array(grad_output, copy=True)\n",
    "        dx[x <= 0] = 0  \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Источник: https://github.com/IssamLaradji/NeuralNetworks/blob/master/multilayer_perceptron/base.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (1 балл).**\n",
    "\n",
    "Используя указанные прототипы, реализуйте полносвязный слой, выход которого вычисляется следующим образом (подробнее в соответствующей [лекции](https://github.com/esokolov/ml-course-hse/blob/master/2017-fall/lecture-notes/lecture11-dl.pdf)):\n",
    "\n",
    "$$f(v; W, b)= Wv + b, $$\n",
    "\n",
    "где\n",
    "* v — выход предыдущего слоя (вектор размера num_inputs);\n",
    "* W — матрица весов [num_inputs, num_outputs];\n",
    "* b — столбец свободных членов (вектор размера num_outputs).\n",
    "\n",
    "При создании полносвязного слоя веса $W, \\; b$ необходимо проинициализировать веса с помощью GLOROT (какой именно вариант неважно). Про GLOROT можно прочитать здесь:\n",
    "1. Простой пост: http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization\n",
    "2. Статья с математикой: http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf\n",
    "\n",
    "При каждом вызове backward() необходимо расчитать градиенты по выходу, используя chain-rule, и сделать один шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_units, output_units, learning_rate=0.1):\n",
    "        \"\"\"\n",
    "        A dense layer is a layer which performs a learned affine transformation:\n",
    "        f(x) = Wx + b\n",
    "\n",
    "        W: matrix of shape [num_inputs, num_outputs]\n",
    "        b: vector of shape [num_outputs]\n",
    "        \"\"\"\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # initialize weights with small random numbers from normal distribution\n",
    "\n",
    "        self.weights = np.random.normal(0, 1/input_units, size=(input_units, output_units))\n",
    "        self.biases = np.random.normal(0, 1/input_units, size=output_units)\n",
    "#         raise NotImplementedError(\"Implement me plz ;(\")\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Perform an affine transformation:\n",
    "        f(x) = <W*x> + b\n",
    "\n",
    "        input shape: [batch, input_units]\n",
    "        output shape: [batch, output units]\n",
    "        \"\"\"\n",
    "        num_batches = input.shape[0]\n",
    "        x_size = int(np.size(input)/num_batches)\n",
    "        x = np.reshape(input, (num_batches, x_size))\n",
    "        output = np.dot(x, self.weights) + self.biases\n",
    "        return output\n",
    "\n",
    "    def backward(self, input, grad_output):\n",
    "        \"\"\"\n",
    "        input shape: [batch, input_units]\n",
    "        grad_output: [batch, output units]\n",
    "\n",
    "        Returns: grad_input, gradient of output w.r.t input\n",
    "        \"\"\"\n",
    "        num_batches = input.shape[0]\n",
    "        x_size = int(np.size(input)/num_batches)\n",
    "        x = np.reshape(input, (num_batches, x_size))\n",
    "        dx = np.dot(grad_output, self.weights.T)\n",
    "        dw = np.dot(grad_output.T, x)\n",
    "        db = np.dot(grad_output.T, np.ones(grad_output.shape[0]))\n",
    "        update = -self.learning_rate*dw.T\n",
    "        self.weights += update \n",
    "        update = -self.learning_rate*db\n",
    "        self.biases += update\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Источник: https://github.com/huyouare/CS231n/blob/master/assignment2/cs231n/layers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3 (1 балл).**\n",
    "\n",
    "Как было сказано ранее, в качестве функционала качества в данной задаче мы будем использовать кросс-энтропию. Используя прототипы ниже, реализуйте вычисление данного функционала и его градиента по выходам графа вычислений.\n",
    "\n",
    "Кросс-энтропия предполагает, что модель для каждого объекта выдает вероятности принадлежности к каждому из $K$ классов, т.е. что для одного объекта все $K$ вероятностей неотрицательны и суммируются в 1. В нашем же случае в построении графа участвуют только полносвязный и ReLU слои, а потому выходы графа не являются вероятностями — как правило, в этом случае прогноз $a(x)$ модели нормируется при помощи функции softmax следующим образом:\n",
    "\n",
    "$$\\text{softmax}(a_k(x)) = \\frac{\\exp(a_k(x))}{\\sum_{k=1}^K \\exp(a_k(x))}.$$\n",
    "\n",
    "При реализации указанных функций предполагается, что переданные в качестве параметров оценки принадлежности объектов классам не являются нормированными (их еще называют логитами), но при вычислении указанных величин используйте указанное выше преобразование для приведения этих оценок к корректному виду."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_crossentropy_with_logits(logits, y_true):\n",
    "    \"\"\"\n",
    "    Compute crossentropy from logits and ids of correct answers\n",
    "    logits shape: [batch_size, num_classes]\n",
    "    reference_answers: [batch_size]\n",
    "    output is a number\n",
    "    \"\"\"\n",
    "    # softmax\n",
    "    logits_exp = np.exp(logits)\n",
    "    logits_exp_sum = np.sum(logits_exp, axis = 1, keepdims=True)\n",
    "    probabilities = logits_exp / logits_exp_sum\n",
    "    #cross-entropy\n",
    "    log_probabilities = np.log(probabilities+1e-9)\n",
    "    N = probabilities.shape[0]\n",
    "    loss = -np.sum(log_probabilities[range(N), y_true])/N\n",
    "    return loss\n",
    "\n",
    "def grad_softmax_crossentropy_with_logits(logits, y_true):\n",
    "    \"\"\"\n",
    "    Compute crossentropy gradient from logits and ids of correct answers\n",
    "    Output should be divided by batch_size, so any layer update can be simply computed as sum of object updates.\n",
    "    logits shape: [batch_size, num_classes]\n",
    "    reference_answers: [batch_size]\n",
    "    \"\"\"\n",
    "    logits_exp = np.exp(logits)\n",
    "    logits_exp_sum = np.sum(logits_exp, axis = 1, keepdims=True)\n",
    "    probabilities = logits_exp / logits_exp_sum\n",
    "    dloss = probabilities\n",
    "    batch_size = y_true.shape[0]\n",
    "    dloss[range(batch_size), y_true] -= 1\n",
    "    dloss /= batch_size\n",
    "    return dloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Источник: https://github.com/huyouare/CS231n/blob/master/assignment2/cs231n/classifiers/neural_net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Реализация и применение графа вычислений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы научимся объединять слои в единый граф вычислений, а также использовать его для прямого прохода (вычисления прогнозов на объектах) и обратного прохода (обновление обучаемых параметров графа), после чего у нас появится возможность обучить граф. Для простоты реализации будем считать, что в нашем случае граф вычислений задается как список (python list) слоёв из числа реализованных ранее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведен код для скачивания датасета MNIST с официального сайта. Датасет делится на тренировочную и тестовую части. Тренировочная дополнительно разбивается на тренировочную и валидационную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import gzip\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def load_mnist(flatten=False):\n",
    "    \"\"\"taken from https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py\"\"\"\n",
    "    # We first define a download function, supporting both Python 2 and 3.\n",
    "\n",
    "    def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "        print(\"Downloading %s\" % filename)\n",
    "        urlretrieve(source + filename, filename)\n",
    "\n",
    "    # We then define functions for loading MNIST images and labels.\n",
    "    # For convenience, they also download the requested files if needed.\n",
    "\n",
    "    def load_mnist_images(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the inputs in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "        # following the shape convention: (examples, channels, rows, columns)\n",
    "        data = data.reshape(-1, 1, 28, 28)\n",
    "        # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "        # (Actually to range [0, 255/256], for compatibility to the version\n",
    "        # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
    "        return data / np.float32(256)\n",
    "\n",
    "    def load_mnist_labels(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the labels in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        # The labels are vectors of integers now, that's exactly what we want.\n",
    "        return data\n",
    "\n",
    "    # We can now download and read the training and test set images and labels.\n",
    "    X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "    y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "    X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "    y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    # We reserve the last 10000 training examples for validation.\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "    \n",
    "    if flatten:\n",
    "        X_train = X_train.reshape([X_train.shape[0], -1])\n",
    "        X_val = X_val.reshape([X_val.shape[0], -1])\n",
    "        X_test = X_test.reshape([X_test.shape[0], -1])\n",
    "\n",
    "    # We just return all the arrays in order, as expected in main().\n",
    "    # (It doesn't matter how we do this as long as we can read them again.)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на несколько объектов из этого датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAF1CAYAAADx1LGMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1135ffac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_mnist(flatten=True)\n",
    "\n",
    "plt.figure(figsize=[6, 6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title(\"Label: %i\"%y_train[i])\n",
    "    plt.imshow(X_train[i].reshape([28, 28]),cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (2 балла).**\n",
    "\n",
    "Используя прототип ниже, реализуйте прямой и обратный проход по графу вычислений и функцию для получения предсказаний метки класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):\n",
    "        \"\"\"\n",
    "        layers — list of Layer objects\n",
    "        \"\"\"\n",
    "        \n",
    "        self.layers = layers\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Compute activations of all network layers by applying them sequentially.\n",
    "        Return a list of activations for each layer. \n",
    "        Make sure last activation corresponds to network logits.\n",
    "        \"\"\"\n",
    "        \n",
    "        activations = []\n",
    "        input = X\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            input = layer.forward(input)\n",
    "            activations.append(input)\n",
    "            \n",
    "        assert len(activations) == len(self.layers)\n",
    "        return activations\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use network to predict the most likely class for each sample.\n",
    "        \"\"\"\n",
    "        logits = self.forward(X)[-1]\n",
    "        logits_exp = np.exp(logits)\n",
    "        logits_exp_sum = np.sum(logits_exp, axis = 1, keepdims=True)\n",
    "        probabilities = logits_exp / logits_exp_sum\n",
    "        prediction = np.argmax(probabilities, axis=1)\n",
    "        return prediction\n",
    "\n",
    "    def backward(self, X, y):\n",
    "        \"\"\"\n",
    "        Train your network on a given batch of X and y.\n",
    "        You first need to run forward to get all layer activations.\n",
    "        Then you can run layer.backward going from last to first layer.\n",
    "\n",
    "        After you called backward for all layers, all Dense layers have already made one gradient step.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the layer activations\n",
    "        layer_activations = self.forward(X)\n",
    "        layer_inputs = [X] + layer_activations  # layer_input[i] is an input for network[i]\n",
    "        logits = layer_activations[-1]\n",
    "\n",
    "        # Compute the loss and the initial gradient\n",
    "        loss = softmax_crossentropy_with_logits(logits, y)\n",
    "        loss_grad = grad_softmax_crossentropy_with_logits(logits, y)\n",
    "\n",
    "        # propagate gradients through network layers using .backward\n",
    "        # hint: start from last layer and move to earlier layers\n",
    "        for l, layer in reversed(list(enumerate(self.layers))):\n",
    "            layer = self.layers[l]\n",
    "            input_x = layer_inputs[l]\n",
    "            loss_grad = layer.backward(input_x, loss_grad)\n",
    "\n",
    "        return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = []\n",
    "hidden_layers_size = 40\n",
    "layers.append(Dense(X_train.shape[1], hidden_layers_size))\n",
    "layers.append(ReLU())\n",
    "layers.append(Dense(hidden_layers_size, hidden_layers_size))\n",
    "layers.append(ReLU())\n",
    "layers.append(Dense(hidden_layers_size, 10))\n",
    "\n",
    "model = NeuralNetwork(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все готово для запуска обучения. Если все реализовано корректно, то точность классификации на валидационном множестве должна превысить 97%. \n",
    "\n",
    "Ниже определена функции для итерации по батчам, принимающая на вход картинки, матки классов, а также размер батча и флаг отвечающий за перемешивание примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False, seed=1234):\n",
    "    assert len(inputs) == len(targets)\n",
    "    \n",
    "    indices = np.arange(len(inputs)).astype(np.int32)\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    \n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        batch = indices[start_idx:start_idx + batchsize]\n",
    "        \n",
    "        yield inputs[batch], targets[batch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведены функции для обучения модели и отслеживания значения loss на тренироворочной части и на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "train_log = []\n",
    "val_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n",
      "Train accuracy: 0.98286\n",
      "Val accuracy: 0.9644\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwm+MMSHGCr8xxoQYK/zGGBNi/j9akZmmy+EDMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1253371d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    for x_batch, y_batch in iterate_minibatches(X_train, y_train, batchsize=32, shuffle=True):\n",
    "        model.backward(x_batch, y_batch)\n",
    "    \n",
    "    train_log.append(np.mean(model.predict(X_train) == y_train))\n",
    "    val_log.append(np.mean(model.predict(X_val) == y_val))\n",
    "    \n",
    "    clear_output()\n",
    "    print(\"Epoch\", epoch)\n",
    "    print(\"Train accuracy:\", train_log[-1])\n",
    "    print(\"Val accuracy:\", val_log[-1])\n",
    "    plt.plot(train_log, label='train accuracy')\n",
    "    plt.plot(val_log, label='val accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Дополнительные слои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части предлагается реализовать сверточный слой и слой maxpooling, а также разработать свою архитектуру графа вычислений с их использованием для повышения качества на валидационной выборке.\n",
    "\n",
    "**Задание 6 (2 балла).** Реализуйте сверточный слой.\n",
    "\n",
    "Рассмотрим один сверточный слой. Пусть на вход поступает изображение $X^l$ с $channels$ каналами, а сверточный слой $W$ имеет размер $k_1 \\times k_2 \\times channels$. Тогда применение слоя можно выразить следующим образом:\n",
    "\n",
    "$$x_{ij}^{l} = \\sum_{m=0}^{k_1 - 1} \\sum_{n=0}^{k_2 - 1} \\sum_{c=0}^{channels} w_{m, n, c}^{l} x_{i+m, j+n, c}^{l-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def im2col(x, kernel_height, kernel_width):\n",
    "    [batch, in_channels, h, w] = x.shape\n",
    "    h_out = h - kernel_height + 1\n",
    "    w_out = w - kernel_width + 1\n",
    "    col = np.zeros((kernel_height*kernel_width*in_channels,\n",
    "                    int(((in_channels*kernel_height*kernel_width*w_out*h_out -1) % (h_out*w_out))*batch + batch)))\n",
    "    for b in range(batch):\n",
    "        for k in range(in_channels*kernel_height*kernel_width*h_out*w_out):\n",
    "            pp = int(k / (h_out*w_out))\n",
    "            qq = int(k % (h_out*w_out))\n",
    "            d0 = int(pp / kernel_height / kernel_width)\n",
    "            i0 = int(qq / w_out) + int((pp / kernel_width) % kernel_height)\n",
    "            j0 = int(qq % w_out) + int(pp % kernel_width)\n",
    "#             print (b, qq)\n",
    "            col[pp, batch*qq + b] = x[b, d0, i0, j0]\n",
    "    return col\n",
    "\n",
    "def col2im(col, x_shape, kernel_height, kernel_width):\n",
    "    [batch, in_channels, h, w] = x_shape\n",
    "    h_out = h - kernel_height + 1\n",
    "    w_out = w - kernel_width + 1\n",
    "    x = np.zeros(x_shape)\n",
    "    for b in range(batch):\n",
    "        for k in range(in_channels*kernel_height*kernel_width*h_out*w_out):\n",
    "            pp = int(k / (h_out*w_out))\n",
    "            qq = int(k % (h_out*w_out))\n",
    "            d0 = int(pp / kernel_height / kernel_width)\n",
    "            i0 = int(qq / w_out) + int((pp / kernel_width) % kernel_height)\n",
    "            j0 = int(qq % w_out) + int(pp % kernel_width)\n",
    "#             print (b, qq)\n",
    "            x[b, d0, i0, j0] += col[pp, batch*qq + b].T\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Conv2d(Layer):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, learning_rate=0.1):\n",
    "        \"\"\"\n",
    "        A convolutional layer with out_channels kernels of kernel_size.\n",
    "\n",
    "        in_channels — number of input channels\n",
    "        out_channels — number of convolutional filters\n",
    "        kernel_size — tuple of two numbers: k_1 and k_2\n",
    "\n",
    "        Initialize required weights.\n",
    "        \"\"\"\n",
    "        self.kernel_size = kernel_size\n",
    "#         self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.weights = np.random.normal(0, 2/(in_channels + out_channels), \n",
    "                                        size=(in_channels, out_channels, kernel_size[0], kernel_size[1]))\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Perform convolutional transformation:\n",
    "\n",
    "        input shape: [batch, in_channels, h, w]\n",
    "        output shape: [batch, out_channels, h_out, w_out]\n",
    "        \"\"\"\n",
    "        [batch, in_channels, h, w] = input.shape\n",
    "        h_out = h - self.kernel_size[0] + 1\n",
    "        w_out = w - self.kernel_size[1] + 1\n",
    "        output = np.zeros((batch, self.out_channels, h_out, w_out))\n",
    "#         for b in range(batch):\n",
    "#             for ch in range(self.out_channels):\n",
    "#                 for x in range(w_out):  \n",
    "#                     for y in range(h_out):\n",
    "#                         output[b, ch, y, x] = (self.weights[:, ch, :, :] * \n",
    "#                                          input[b, :, y:y + self.kernel_size[0],\n",
    "#                                          x:x + self.kernel_size[1]]).sum()\n",
    "\n",
    "        x_cols = im2col(input, self.kernel_size[0], self.kernel_size[1])\n",
    "#         print(x_cols.shape)\n",
    "        output = self.weights.reshape(self.out_channels, -1).dot(x_cols)\n",
    "        output = output.reshape(self.out_channels, h_out, w_out, batch)\n",
    "        output = output.transpose(3, 0, 1, 2)\n",
    "        return output\n",
    "\n",
    "    def backward(self, input, grad_output):\n",
    "        \"\"\"\n",
    "        Compute gradients w.r.t input and weights and update weights\n",
    "        \"\"\"\n",
    "#         [batch, in_channels, h, w] = input.shape\n",
    "#         dx = np.zeros_like(input)\n",
    "#         dw = np.zeros_like(self.weights)\n",
    "        x_cols = im2col(input, self.kernel_size[0], self.kernel_size[1])\n",
    "        grad_output_col = grad_output.transpose(1, 2, 3, 0).reshape(self.out_channels, -1)\n",
    "        dw = grad_output_col.dot(x_cols.T).reshape(self.weights.shape)\n",
    "\n",
    "        dx_cols = self.weights.reshape(self.out_channels, -1).T.dot(grad_output_col)\n",
    "        dx = col2im(dx_cols, input.shape, self.kernel_size[0], self.kernel_size[1])\n",
    "#         for b in range(batch):\n",
    "#             for ch in range(self.out_channels):\n",
    "#                 for x in range(w_out):  \n",
    "#                     for y in range(h_out):\n",
    "#                         dx[b, :, y:y + self.kernel_size[0], x:x + kernel_size[1]] += \n",
    "#                         self.weights[:, ch, :, :] * grad_output[b, ch, y, x]\n",
    "#                         dw[:, ch, :, :] += input[:, y:y + self.kernel_size[0], x:x + kernel_size[1]]\n",
    "#                         * grad_output[b, ch, y, x]\n",
    "        \n",
    "        update = - dw * self.learning_rate\n",
    "        self.weights += update\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Источник: https://github.com/huyouare/CS231n/blob/master/assignment2/cs231n/layers.py\n",
    "\n",
    "A Simple and Efficient Implementation of im2col in\n",
    "Convolution Neural Networks by Hao Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7 (1 балл).** Реализуйте слой макспулинга.\n",
    "\n",
    "Ниже, на картинке, можно увидеть пример применения операции макспулинга с ядром размера 2x2 (слой применяется раздельно для каждого канала изображения).\n",
    "\n",
    "<img src=\"https://cambridgespark.com/content/tutorials/convolutional-neural-networks-with-keras/figures/pool.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Maxpool2d(Layer):\n",
    "    def __init__(self, kernel_size):\n",
    "        \"\"\"\n",
    "        A maxpooling layer with kernel of kernel_size.\n",
    "        This layer donwsamples [kernel_size, kernel_size] to\n",
    "        1 number which represents maximum.\n",
    "\n",
    "        Stride description is identical to the convolution\n",
    "        layer. But default value we use is kernel_size to\n",
    "        reduce dim by kernel_size times.\n",
    "\n",
    "        This layer does not have any learnable parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        self.stride = kernel_size\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Perform maxpooling transformation:\n",
    "\n",
    "        input shape: [batch, in_channels, h, w]\n",
    "        output shape: [batch, out_channels, h_out, w_out]\n",
    "        \"\"\"\n",
    "        [batch, in_channels, h, w] = input.shape\n",
    "        if h % self.kernel_size == 0 and w % self.kernel_size == 0:\n",
    "            x_reshaped = input.reshape(batch, in_channels, int(h/ self.kernel_size), self.kernel_size,\n",
    "                                      int(w/self.kernel_size), self.kernel_size)\n",
    "            return x_reshaped.max(axis=3).max(axis=4)\n",
    "        else:\n",
    "            h_out = int((h - self.kernel_size)/self.stride + 1)\n",
    "            w_out = int((w - self.kernel_size)/self.stride + 1)\n",
    "            output = np.zeros((batch, in_channels, h_out, w_out))\n",
    "            for b in range(batch):\n",
    "                for x in range(w_out):  \n",
    "                    for y in range(h_out):\n",
    "                        y1 = y * self.stride\n",
    "                        y2 = y * self.stride + self.kernel_size\n",
    "                        x1 = x * self.stride\n",
    "                        x2 = x * self.stride + self.kernel_size\n",
    "                        window = input[b, :, x1:x2, y1:y2]\n",
    "                        output[b, :, x, y] = np.max(window.reshape((in_channels, self.kernel_size**2)), axis=1)\n",
    "#             print(\"OK\")\n",
    "            return output\n",
    "                        \n",
    "\n",
    "    def backward(self, input, grad_output):\n",
    "        \"\"\"\n",
    "        Compute gradient of loss w.r.t. Maxpool2d input\n",
    "        \"\"\"\n",
    "        [batch, in_channels, h, w] = input.shape\n",
    "        h_out = int((h - self.kernel_size)/self.stride + 1)\n",
    "        w_out = int((w - self.kernel_size)/self.stride + 1)\n",
    "        dx = np.zeros_like(input)\n",
    "        for b in range(batch):\n",
    "            for ch in range(in_channels):\n",
    "                for x in range(w_out):  \n",
    "                    for y in range(h_out):\n",
    "                        y1 = y * self.stride\n",
    "                        y2 = y * self.stride + self.kernel_size\n",
    "                        x1 = x * self.stride\n",
    "                        x2 = x * self.stride + self.kernel_size\n",
    "                        window = input[b, ch, x1:x2, y1:y2].reshape((self.kernel_size**2))\n",
    "                        window = (window == window.max())\n",
    "                        dx[b, ch, x1:x2, y1:y2] = window.reshape(\n",
    "                            (self.kernel_size,self.kernel_size)) * grad_output[b, ch, x, y]\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 8 (1 балл).** Реализуйте слой для перевода n-мерного тензора в матрицу. Данный слой понадобится вам после использования сверточных слоев для перевода четырехмерного тензора в матрицу и дальнейшего использования результата в полносвязном слое для предсказания ненормированных вероятностей классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(Layer):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        This layer does not have any parameters\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input shape: [batch_size, channels, feature_nums_h, feature_nums_w]\n",
    "        output shape: [batch_size, channels * feature_nums_h * feature_nums_w]\n",
    "        \"\"\"\n",
    "        return input.reshape(input.shape[0], -1)\n",
    "\n",
    "    def backward(self, input, grad_output):\n",
    "        \"\"\"\n",
    "        Compute gradient of loss w.r.t. Flatten input\n",
    "        \"\"\"\n",
    "        return grad_output.reshape(input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 9 (1 балл).** Подберите архитектуру сети, используя сверточные слои и слои макспулинга и превзойдите качество полносвязной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "# layers.append(Conv2d(1, 4, (3, 3)))#in_channels, out_channels, kernel_size\n",
    "layers.append(ReLU())\n",
    "layers.append(Maxpool2d(2))\n",
    "# layers.append(Conv2d(1, hidden_layers_size, (3, 3)))\n",
    "# layers.append(ReLU())\n",
    "# layers.append(Maxpool2d(2))\n",
    "layers.append(Flatten())\n",
    "layers.append(Dense(1*14*14, 10))\n",
    "# layers.append(ReLU())\n",
    "\n",
    "model = NeuralNetwork(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "train_log = []\n",
    "val_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1562 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid integer data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-6758aa88b30a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6e6cf33061b6>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Get the layer activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mlayer_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mlayer_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer_activations\u001b[0m  \u001b[0;31m# layer_input[i] is an input for network[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_activations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6e6cf33061b6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2358c2ee66ba>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, int_type)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'iu'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid integer data type.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid integer data type."
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    for x_batch,y_batch in iterate_minibatches(X_train, y_train, batchsize=32, shuffle=True):\n",
    "        model.backward(x_batch.reshape((-1, 1, 28, 28)), y_batch)\n",
    "    \n",
    "    train_log.append(np.mean(model.predict(X_train.reshape((-1, 1, 28, 28))) == y_train))\n",
    "    val_log.append(np.mean(model.predict(X_val.reshape((-1, 1, 28, 28))) == y_val))\n",
    "    \n",
    "    clear_output()\n",
    "    print(\"Epoch\", epoch)\n",
    "    print(\"Train accuracy:\", train_log[-1])\n",
    "    print(\"Val accuracy:\", val_log[-1])\n",
    "    plt.plot(train_log, label='train accuracy')\n",
    "    plt.plot(val_log, label='val accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 4. Мемы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 10 (0.2 балла).** Какой мем из уже прошедшего 2k17 года вам запомнился больше всего? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 11 (0.2 балла).** А какой из появившихся в 2k!8 вам понравился больше всего?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 12 (0.2 балла).** А здесь напишите фидбек по заданию :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
